{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOZEqj4XsTIUX2l6C7XsT3i"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q autogen gradio\n",
        "\n",
        "import os\n",
        "from autogen import AssistantAgent\n",
        "from autogen import UserProxyAgent\n",
        "\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "phapE7je1lHi",
        "outputId": "e6130148-1f95-4377-8e64-934deb16e657"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/826.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m614.4/826.8 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m826.8/826.8 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Carregando chave da API Gemini salva no Colab\n",
        "GOOGLE_API_KEY = userdata.get(\"chave_api\")\n",
        "genai.configure(api_key=GOOGLE_API_KEY)\n",
        "\n",
        "# Criando o agente assistente com Gemini\n",
        "assistant = AssistantAgent(\n",
        "    name=\"ORIENS\",\n",
        "    llm_config={\n",
        "        \"config_list\": [\n",
        "            {\n",
        "                \"model\": \"gemini-2.0-flash\",\n",
        "                \"api_key\": GOOGLE_API_KEY,\n",
        "                \"base_url\": \"https://generativelanguage.googleapis.com/v1beta\",\n",
        "                \"api_type\": \"google\",\n",
        "            }\n",
        "        ]\n",
        "    },\n",
        "    system_message=\"\"\"\n",
        "    \"VocÃª Ã© um analista de dados experiente e proativo, responsÃ¡vel por explorar e responder perguntas relacionadas a arquivos contidos em um arquivo 202401_NFs.zip localizado na pasta content.\n",
        "\n",
        "Esse 202401_NFs.zip contÃ©m arquivos que, uma vez extraÃ­dos e carregados, geram dois principais: 202401_NFs_Cabecalho.csv e 202401_NFs_Itens.csv.\n",
        "\n",
        "DescriÃ§Ã£o esperada dos dados:\n",
        "\n",
        "202401_NFs_Cabecalho.csv: contÃ©m dados agregados de pedidos ou transaÃ§Ãµes.\n",
        "\n",
        "202401_NFs_Itens.csv: contÃ©m a lista de produtos ou serviÃ§os associados a cada pedido.\n",
        "\n",
        "Suas responsabilidades incluem:\n",
        "\n",
        "Ler o arquivo 202401_NFs.zip diretamente da pasta content, extraindo e carregando os arquivos relevantes.\n",
        "\n",
        "Inspecionar, limpar e preparar os dados se necessÃ¡rio (tratamento de nulos, tipos de dados, normalizaÃ§Ã£o, etc.).\n",
        "\n",
        "Utilizar Python e bibliotecas como pandas, numpy, matplotlib, seaborn, ou outras adequadas ao problema.\n",
        "\n",
        "Apresentar os resultados de forma clara e objetiva, incluindo:\n",
        "\n",
        "CÃ³digo limpo e bem comentado;\n",
        "\n",
        "Tabelas ou grÃ¡ficos simples e informativos, quando relevantes;\n",
        "\n",
        "Resumo interpretativo com os principais insights.\n",
        "\n",
        "Evite jargÃµes desnecessÃ¡rios e mantenha uma linguagem acessÃ­vel. Foque em entregar anÃ¡lises Ãºteis, diretas e acionÃ¡veis com base no conteÃºdo dos arquivos. responder Ã s perguntas de forma clara, **direta** e **resumida**, como em uma conversa estilo chatbot.\n",
        "\n",
        "Sempre que possÃ­vel, **responda Ã  pergunta de forma clara**.\n",
        "Evite explicar o que vai fazer a menos que o usuÃ¡rio peÃ§a.\n",
        "\n",
        "Raciocine mas nÃ£o mostre seu raciocÃ­nio ao usuÃ¡rio, apenas a **resposta final**. Se nÃ£o souber, diga claramente\"\"\"\n",
        ")"
      ],
      "metadata": {
        "id": "htb68V9L1nJ6"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user = UserProxyAgent(\n",
        "    name=\"UsuÃ¡rio\",\n",
        "    human_input_mode=\"ALWAYS\",\n",
        "    max_consecutive_auto_reply=3,\n",
        "    is_termination_msg=lambda x: x.get(\"content\", \"\").strip().lower() == \"sair\",\n",
        "    code_execution_config={\"use_docker\": False},\n",
        "    system_message=\"Execute o cÃ³digo fornecido e relate o resultado. Responda 'sair' para encerrar.\",\n",
        ")"
      ],
      "metadata": {
        "id": "LKhxmObb1x57"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assistant.enable_print = False\n",
        "user.enable_print = False"
      ],
      "metadata": {
        "id": "3QpeNNTh2AJL"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleChatManager:\n",
        "    def __init__(self, assistant_agent):\n",
        "        self.assistant = assistant_agent\n",
        "        self.history = []\n",
        "\n",
        "    def ask(self, question):\n",
        "        self.history.append({\"role\": \"user\", \"content\": question})\n",
        "        reply = self.assistant.generate_reply(messages=self.history)\n",
        "        if isinstance(reply, dict):\n",
        "            resposta = reply.get(\"content\", \"\").strip()\n",
        "            self.history.append({\"role\": \"assistant\", \"content\": resposta})\n",
        "            return resposta\n",
        "        else:\n",
        "            return \"Erro ao gerar resposta.\"\n",
        "\n",
        "chat_manager = SimpleChatManager(assistant)"
      ],
      "metadata": {
        "id": "qxwZ6nhz2CV4"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr"
      ],
      "metadata": {
        "id": "zGIkFnmM2Fq0"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def responder(pergunta):\n",
        "    if pergunta.strip().lower() in [\"sair\", \"exit\", \"fechar\"]:\n",
        "        return \"ğŸ‘‹ Encerrando a sessÃ£o. AtÃ© a prÃ³xima!\"\n",
        "    resposta = chat_manager.ask(pergunta)\n",
        "    return resposta\n",
        "\n",
        "iface = gr.Interface(\n",
        "    fn=responder,\n",
        "    inputs=gr.Textbox(label=\"Pergunte algo ao ORIENS\"),\n",
        "    outputs=gr.Textbox(label=\"Resposta do ORIENS\"),\n",
        "    title=\"ğŸ’¬ Chat com ORIENS - Agente de Dados\",\n",
        "    description=\"FaÃ§a perguntas sobre os arquivos de notas fiscais (202401_NFs.zip) disponÃ­veis na pasta /content.\",\n",
        "    theme=\"soft\",\n",
        ")\n",
        "\n",
        "iface.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "collapsed": true,
        "id": "VwxUccHf2LlW",
        "outputId": "29e62303-ee0e-4c7e-b1de-e8abc600d519"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://b5f61f3e49e028c58c.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://b5f61f3e49e028c58c.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    }
  ]
}